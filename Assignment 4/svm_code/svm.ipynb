{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.loadtxt('y_train1-1.csv', delimiter=',')\n",
    "y_test = np.loadtxt('y_test1-1.csv', delimiter=',')\n",
    "X_train = np.loadtxt('X_train_binary.csv', delimiter=',')\n",
    "X_test = np.loadtxt('X_test_binary.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 class frequency is 0.5467\n",
      "-1.0 class frequency is 0.4533\n"
     ]
    }
   ],
   "source": [
    "cnt_class = {}\n",
    "for y in y_train:\n",
    "    if y in cnt_class:\n",
    "        cnt_class[y] += 1\n",
    "    else:\n",
    "        cnt_class[y] = 1\n",
    "totalPoints = 150     # the number of total data points\n",
    "for key in cnt_class:\n",
    "    print(str(key) + \" class frequency is \" + '%.4f' % (cnt_class[key] / totalPoints))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training data: 150\n",
      "number of test data: 164\n"
     ]
    }
   ],
   "source": [
    "number_of_training = np.shape(X_train)[0] # 150 x 61\n",
    "number_of_test = np.shape(X_test)[0]\n",
    "print(\"number of training data: \" + str(number_of_training))\n",
    "print(\"number of test data: \" + str(number_of_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the mean and standard deviation of the training features\n",
    "mean_of_training = np.mean(X_train, axis=0) \n",
    "standard_of_training = np.std(X_train, axis=0)\n",
    "# to normalize data\n",
    "norm_train = (X_train - mean_of_training) / standard_of_training\n",
    "norm_test = (X_test - mean_of_training) / standard_of_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"mean of original test data:\")\n",
    "# print(np.around(np.mean(X_test, axis=0),2))\n",
    "# print(\"variance of original test data:\")\n",
    "# print(np.around(np.var(X_test, axis=0), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of normalized features in the test data:\n",
      "[ 0.09  0.17 -0.06 -0.08 -0.04 -0.11 -0.1  -0.21  0.27  0.08  0.01  0.06\n",
      "  0.01  0.    0.13  0.02  0.13  0.13  0.03  0.1   0.48  0.11  0.05 -0.12\n",
      "  0.11  0.02 -0.1  -0.13 -0.18  0.01 -0.03  0.    0.2  -0.01 -0.08  0.17\n",
      "  0.3   0.18  0.05 -0.02  0.08  0.22  0.04 -0.12 -0.03  0.1   0.12  0.1\n",
      " -0.07 -0.05 -0.13  0.04 -0.    0.01  0.23 -0.04  0.14  0.14  0.04 -0.01\n",
      " -0.06]\n",
      "Variance of normalized features in the test data:\n",
      "[ 1.93  7.28  0.79  0.74  0.86  0.98  1.07  2.88  2.97  1.48  1.09  1.14\n",
      "  1.12  1.24  1.27  1.01  1.13  3.89  5.71  5.   54.28  1.44  1.02  0.97\n",
      "  0.85  1.16  0.59  0.8   0.4   1.22  1.03  1.    1.03  1.07  0.82  4.91\n",
      " 11.01  0.97  0.81  0.89  2.44  2.21  1.51  0.89  1.32  0.82  1.2   2.23\n",
      "  1.22  0.93  1.19  1.31  1.39  0.86  1.94  1.03  1.07  1.21  1.74  1.87\n",
      "  1.01]\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean of normalized features in the test data:\")\n",
    "print(np.around(np.mean(norm_test, axis=0),2))\n",
    "print(\"Variance of normalized features in the test data:\")\n",
    "print(np.around(np.var(norm_test, axis=0), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the best C: 1\n",
      "the best gamma: 0.01\n"
     ]
    }
   ],
   "source": [
    "# values of hyperparameters gamma and C\n",
    "C = [10**n for n in range(-2, 5)]\n",
    "gamma = [10**n for n in range(-4, 3)]\n",
    "\n",
    "params = [{\"kernel\":[\"rbf\"],\n",
    "          \"C\":C, \n",
    "          \"gamma\": gamma}]\n",
    "\n",
    "# 5-fold cross-validation using grid-search\n",
    "grid = GridSearchCV(svm.SVC(), param_grid = params, cv=5, scoring='accuracy') \n",
    "grid.fit(norm_train, y_train)\n",
    "\n",
    "best_C = grid.best_params_[\"C\"]\n",
    "best_gamma = grid.best_params_[\"gamma\"]\n",
    "print('the best C:',  str(best_C))  \n",
    "print('the best gamma:',  str(best_gamma)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training error: 0.046666666666666634\n",
      "test error: 0.20731707317073167\n"
     ]
    }
   ],
   "source": [
    "# train an SVM with the best hyperparameters using the complete training dataset\n",
    "model = svm.SVC(kernel = 'rbf', C = best_C, gamma = best_gamma)\n",
    "model.fit(norm_train, y_train)\n",
    "\n",
    "# training error\n",
    "training_predictions = model.predict(norm_train)\n",
    "training_accurracy = accuracy_score(y_train, training_predictions)\n",
    "print('training error:', 1 - training_accurracy)\n",
    "\n",
    "# test error\n",
    "test_predictions = model.predict(norm_test)\n",
    "test_accurracy = accuracy_score(y_test, test_predictions)\n",
    "print('test error:',1 - test_accurracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of bounded SV: {0.001: 136, 10000: 0}\n",
      "number of free SV: {0.001: 0, 10000: 72}\n"
     ]
    }
   ],
   "source": [
    "number_of_bounded = {} # the number of bounded SV and its corresponding value of C\n",
    "number_of_free = {} # the number of free SV and its corresponding value of C\n",
    "\n",
    "# number of C is drastically increased and decreased\n",
    "# (the best of value of C is 1)\n",
    "C = [0.001, 10000]\n",
    "\n",
    "for c in C:\n",
    "    model_c = svm.SVC(kernel='rbf', C=c, gamma=best_gamma)\n",
    "    model_c.fit(norm_train, y_train)\n",
    "    # get the set of alpha\n",
    "    alphas = np.abs(model_c.dual_coef_)\n",
    "    # alpha needs to large than zero\n",
    "    valid_alphas = alphas[alphas > 0]\n",
    "    # to get the number of bounded and free sv when C = c\n",
    "    number_of_bounded_c = alphas[alphas == c].shape[0]\n",
    "    number_of_free_c = alphas[alphas < c].shape[0]\n",
    "    number_of_bounded[c] = number_of_bounded_c\n",
    "    number_of_free[c] = number_of_free_c\n",
    "\n",
    "print('number of bounded SV:', number_of_bounded)\n",
    "print('number of free SV:', number_of_free)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "262b178469be519b47f5ae60cf00d13b02be081e464c908c9747ad0db1572806"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
